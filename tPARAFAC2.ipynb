{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tPARAFAC2 implementation\n",
    "---\n",
    "The present notebook contains the synthetic data generation scheme of the paper along with the implementation of tPARAFAC2 as a constraint of matcouply (https://github.com/MarieRoald/matcouply)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "\n",
    "import numpy as np\n",
    "import tensorly as tl\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from random import choice\n",
    "import pickle\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matcouply\n",
    "from scipy import spatial\n",
    "from matcouply.penalties import MatricesPenalty\n",
    "from tlviz.factor_tools import degeneracy_score,factor_match_score\n",
    "from tensorly.cp_tensor import CPTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic data generation\n",
    "\n",
    "class data_generator():\n",
    "\n",
    "    def __init__(self,\n",
    "                 no_of_concepts,            # Number of structures existing in the data i.e. the rank.\n",
    "                 type_of_drift,             # List (with length equal to no_of_concepts) that contains the type of drift for each structure.\n",
    "                 type_of_change,\n",
    "                 I,\n",
    "                 J,\n",
    "                 K,                         # Tensor dimensions, where K denotes the no of timeslices.\n",
    "                 B_internal_overlap,        # Percentage that describes the overlap between the initial and final concepts in Bs.\n",
    "                 B_external_overlap,        # Percentage that describes the overlap between the columns of Bs.\n",
    "                 sigmoid_kurt,              # Steepness of sigmoid used in incremental drift.\n",
    "                 evolution_prob,            # probabilty of a point 'evolving' in a timeslice (only applicable in incremental drift).\n",
    "                 drift_indices,             # The indices that denote when concept changes in structure.\n",
    "                 change_indices,            # The indices that denote when concept changes in strength.\n",
    "                 noise_eta,                 # Magnitude of noise to add.\n",
    "                 B_external_overlap_when,   # {'start','final'} when there is full overlap between concepts.\n",
    "                 A_negative=False           # {'True','False'} whether to add negative values in A.\n",
    "                 ):\n",
    "\n",
    "        self.I = I\n",
    "        self.J = J\n",
    "        self.K = K\n",
    "\n",
    "        # Some very very basic error chacking\n",
    "        \n",
    "        if len(type_of_drift) != no_of_concepts: \n",
    "            \n",
    "            raise ValueError('type_of_drift != len(no_of_concepts)')\n",
    "\n",
    "        elif len(set(type_of_drift).difference(set(['sudden','gradual','incremental','reoccurring','incremental+reoccurring']))) != 0:\n",
    "\n",
    "            raise ValueError('len(set(type_of_drift).difference(set(\\'sudden\\',\\'gradual\\',\\'incremental\\',\\'reoccurring\\',\\'incremental+reoccuring\\'))) != 0')\n",
    "\n",
    "        elif len(drift_indices) != no_of_concepts:\n",
    "\n",
    "            raise ValueError('len(drift_indices) != no_of_concepts')\n",
    "\n",
    "        elif len(set(type_of_change).difference(set(['increasing','decreasing','periodical','constant']))) != 0:\n",
    "\n",
    "            raise ValueError('len(set(type_of_change).difference(set([\\'increasing\\',\\'decreasing\\',\\'periodical\\',\\'constant\\']))) != 0:')\n",
    "\n",
    "        else:\n",
    "\n",
    "            self.no_of_concepts = no_of_concepts\n",
    "            self.type_of_drift = type_of_drift\n",
    "            self.type_of_change = type_of_change\n",
    "\n",
    "        self.B_external_overlap = B_external_overlap\n",
    "        self.B_internal_overlap = B_internal_overlap\n",
    "        self.evolution_prob = evolution_prob\n",
    "        self.sigmoid_kurt = sigmoid_kurt\n",
    "        self.change_indices = change_indices\n",
    "        self.drift_indices = drift_indices\n",
    "        self.noise_eta = noise_eta\n",
    "        self.B_external_overlap_when = B_external_overlap_when\n",
    "        self.A_negative = A_negative\n",
    "\n",
    "    def sigmoid_(self,x,x0,kurt):\n",
    "        '''\n",
    "        Reutrn sigmoid f(x)=L/(1+exp(e)^(-k(x-x0)))\n",
    "        '''\n",
    "        return 1/(1+np.exp(-1*kurt*(x-x0)))\n",
    "\n",
    "    def _generate_As_(self):\n",
    "        '''\n",
    "        Create and return A factor matrix.\n",
    "        '''\n",
    "\n",
    "        self.A_sets = []\n",
    "\n",
    "        for pattern_no in range(self.no_of_concepts):\n",
    "\n",
    "            self.A_sets.append(np.array([*range(pattern_no*int(self.I/self.no_of_concepts),pattern_no*int(self.I/self.no_of_concepts)+int(self.I/self.no_of_concepts))]))\n",
    "\n",
    "        self.As = np.zeros((self.I,self.no_of_concepts))\n",
    "\n",
    "        for pattern_no in range(self.no_of_concepts):\n",
    "\n",
    "            for index in list(self.A_sets[pattern_no]):\n",
    "\n",
    "                initial_val = np.random.normal(loc=0.5,scale=0.5)\n",
    "                while initial_val > 1 or initial_val <= 0: initial_val = np.random.normal(loc=0.5,scale=0.5)\n",
    "\n",
    "                self.As[index,pattern_no] = initial_val\n",
    "\n",
    "        # Add some negative values in As (iff applicable)\n",
    "        if self.A_negative:\n",
    "            \n",
    "            for i in range(self.As.shape[0]):\n",
    "                for j in range(self.As.shape[1]):\n",
    "                    self.As[i][j] = np.multiply(self.As[i][j],np.random.choice([-1,1]))\n",
    "\n",
    "    def _generate_Bs_(self):\n",
    "        '''\n",
    "        Create and return B factor matrices.\n",
    "        '''\n",
    "\n",
    "        # Generate pattern index sets\n",
    "\n",
    "        self.B_initial_sets = []\n",
    "        self.B_final_sets  = []\n",
    "\n",
    "        for pattern_no in range(self.no_of_concepts): # For each pattern\n",
    "\n",
    "            self.B_initial_sets.append(set())\n",
    "            self.B_final_sets .append(set())\n",
    "\n",
    "            while len(self.B_initial_sets[pattern_no]) < 3 or len(self.B_final_sets [pattern_no]) < 3 : # Need to be at least 3 words in each topic\n",
    "\n",
    "                # Generate a rondom index between the min index of this pattern and the max and divide the indices in the initial and the final set\n",
    "                diff_index = int(np.random.normal(loc=pattern_no*int(self.J/self.no_of_concepts)+(1/2)*int(self.J/self.no_of_concepts),scale=pattern_no*int(self.J/self.no_of_concepts)+(1/4)*int(self.J/self.no_of_concepts)))\n",
    "                self.B_initial_sets[pattern_no] = set([*range(pattern_no*int(self.J/self.no_of_concepts),diff_index)])\n",
    "                self.B_final_sets [pattern_no] = set([*range(diff_index,pattern_no*int(self.J/self.no_of_concepts)+int(self.J/self.no_of_concepts))])\n",
    "                     \n",
    "            # Apply internal overlap (iff applicable)\n",
    "\n",
    "            coin_result = np.random.binomial(1,0.5) # Toss a coin\n",
    "\n",
    "            if coin_result == 1:\n",
    "\n",
    "                for item in self.B_initial_sets[pattern_no]:\n",
    "\n",
    "                    if 100*len(self.B_initial_sets[pattern_no].intersection(self.B_final_sets [pattern_no]))/len(self.B_initial_sets[pattern_no]) >= self.B_internal_overlap: break\n",
    "\n",
    "                    self.B_final_sets[pattern_no].add(item)\n",
    "\n",
    "                for item in self.B_final_sets[pattern_no]:\n",
    "\n",
    "                    if 100*len(self.B_initial_sets[pattern_no].intersection(self.B_final_sets [pattern_no]))/len(self.B_initial_sets[pattern_no]) >= self.B_internal_overlap: break\n",
    "\n",
    "                    self.B_initial_sets[pattern_no].add(item)\n",
    "\n",
    "            else:\n",
    "\n",
    "                for item in self.B_final_sets[pattern_no]:\n",
    "\n",
    "                    if 100*len(self.B_final_sets[pattern_no].intersection(self.B_initial_sets [pattern_no]))/len(self.B_final_sets[pattern_no]) >= self.B_internal_overlap: break\n",
    "\n",
    "                    self.B_initial_sets[pattern_no].add(item)\n",
    "\n",
    "                for item in self.B_initial_sets[pattern_no]:\n",
    "\n",
    "                    if 100*len(self.B_final_sets[pattern_no].intersection(self.B_initial_sets [pattern_no]))/len(self.B_final_sets[pattern_no]) >= self.B_internal_overlap: break\n",
    "\n",
    "                    self.B_final_sets[pattern_no].add(item)   \n",
    "\n",
    "            # if self.type_of_drift[pattern_no] in ['sudden','gradual','reoccurring']: # In case we need the initial and final sets to be similar in size\n",
    "\n",
    "            #     if len(self.B_initial_sets[pattern_no]) > len(self.B_final_sets [pattern_no]):\n",
    "\n",
    "            #         while(len(self.B_initial_sets[pattern_no]) > len(self.B_final_sets [pattern_no])):\n",
    "\n",
    "            #             item = choice(list(self.B_initial_sets[pattern_no]))\n",
    "\n",
    "            #             if item in self.B_final_sets[pattern_no]: continue\n",
    "\n",
    "            #             if abs(len(self.B_initial_sets[pattern_no])-len(self.B_final_sets[pattern_no])) != 1: self.B_initial_sets[pattern_no].remove(item)\n",
    "            #             self.B_final_sets[pattern_no].add(item)\n",
    "\n",
    "            #     if len(self.B_initial_sets[pattern_no]) < len(self.B_final_sets [pattern_no]):\n",
    "\n",
    "            #         while(len(self.B_initial_sets[pattern_no]) < len(self.B_final_sets [pattern_no])):\n",
    "\n",
    "            #             item = choice(list(self.B_final_sets[pattern_no]))\n",
    "\n",
    "            #             if item in self.B_initial_sets[pattern_no]: continue\n",
    "\n",
    "            #             if abs(len(self.B_initial_sets[pattern_no])-len(self.B_final_sets[pattern_no])) != 1: self.B_final_sets[pattern_no].remove(item)\n",
    "            #             self.B_initial_sets[pattern_no].add(item)\n",
    "\n",
    "            #     print(f'{pattern_no}-initial: {len(self.B_initial_sets[pattern_no])} final: {len(self.B_final_sets[pattern_no])}')\n",
    "\n",
    "        # Apply external overlap on B (if applicable)\n",
    "\n",
    "        if self.B_external_overlap > 0:\n",
    "\n",
    "            # print(f'{math.ceil(self.B_external_overlap*self.J/100)} overlapping points.')\n",
    "\n",
    "            for _ in range(math.ceil(self.B_external_overlap*self.J/100)):\n",
    "\n",
    "                while(True):\n",
    "\n",
    "                    concept_no = choice([*range(self.no_of_concepts)]) # choose a random concept\n",
    "\n",
    "                    if self.B_external_overlap_when == 'start':\n",
    "                        index = choice(list(self.B_initial_sets[concept_no])) # choose a random index of the initial set\n",
    "                    else:\n",
    "                        index = choice(list(self.B_final_sets[concept_no])) # choose a random index of the final set\n",
    "\n",
    "                    all_concepts = [i for i in range(self.no_of_concepts)] # create a list of concepts\n",
    "\n",
    "                    concept2remove = []\n",
    "\n",
    "                    for concept_no2 in all_concepts:\n",
    "\n",
    "                        if concept_no == concept_no2: concept2remove.append(concept_no2)\n",
    "\n",
    "                        if self.B_external_overlap_when == 'start' and index in self.B_initial_sets[concept_no2] and concept_no2 not in concept2remove: concept2remove.append(concept_no2)\n",
    "\n",
    "                        if self.B_external_overlap_when == 'final' and index in self.B_final_sets[concept_no2] and concept_no2 not in concept2remove: concept2remove.append(concept_no2)\n",
    "\n",
    "                    if len(concept2remove) == len(all_concepts): continue\n",
    "\n",
    "                    for val in concept2remove:\n",
    "                        all_concepts.remove(val)\n",
    "\n",
    "                    new_structure = choice(all_concepts) # choose randomly one of the other concepts\n",
    "\n",
    "                    if self.B_external_overlap_when == 'start':\n",
    "                        self.B_initial_sets[new_structure].add(index) # add the index to the other structure initial concept\n",
    "                    else:\n",
    "                        self.B_final_sets[new_structure].add(index) # add the index to the other structure initial concept\n",
    "\n",
    "                    break        \n",
    "\n",
    "        # Generate lookup tables of evolution of Bs\n",
    "\n",
    "        self.Bs_lookup = [self.B_initial_sets]\n",
    "        pattern_status = ['initial' for _ in range(self.no_of_concepts)]\n",
    "        \n",
    "        self.pattern_statuses = deepcopy([pattern_status])\n",
    "\n",
    "        items2remove = [set() for i in range(self.no_of_concepts)] # Careful: may work with only one incremental pattern\n",
    "        items2add = [set() for i in range(self.no_of_concepts)]\n",
    "\n",
    "        for t in range(1,self.K):\n",
    "            \n",
    "            temp = deepcopy(self.Bs_lookup[-1])\n",
    "\n",
    "            for pattern_no in range(self.no_of_concepts):\n",
    "\n",
    "                # Sudden\n",
    "                if self.type_of_drift[pattern_no] == 'sudden' and self.drift_indices[pattern_no][0] == t: \n",
    "                    temp[pattern_no] = self.B_final_sets [pattern_no]\n",
    "                    pattern_status[pattern_no] = 'final'\n",
    "\n",
    "                # Gradual\n",
    "                if self.type_of_drift[pattern_no] == 'gradual' and self.drift_indices[pattern_no][0] - t >= 0:\n",
    "\n",
    "                    if self.drift_indices[pattern_no][0] == t:\n",
    "                        temp[pattern_no] = self.B_final_sets [pattern_no]\n",
    "                        pattern_status[pattern_no] = 'final'\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        coin_result = np.random.binomial(1,0.5) # Toss a coin\n",
    "\n",
    "                        if coin_result == 1:\n",
    "                            if pattern_status[pattern_no] == 'initial':\n",
    "                                temp[pattern_no] = self.B_final_sets [pattern_no]\n",
    "                                pattern_status[pattern_no] = 'final'\n",
    "                            elif pattern_status[pattern_no] == 'final':\n",
    "                                temp[pattern_no] = self.B_initial_sets[pattern_no]\n",
    "                                pattern_status[pattern_no] = 'initial'                                                                \n",
    "\n",
    "                # Incremental\n",
    "                if self.type_of_drift[pattern_no] == 'incremental' and pattern_status[pattern_no] == 'initial' and t > self.drift_indices[pattern_no][0]:\n",
    "                    \n",
    "                    for item in temp[pattern_no]:\n",
    "\n",
    "                        if item in items2add[pattern_no]: continue\n",
    "\n",
    "                        # change_prob = self.sigmoid_(t,self.drift_indices[pattern_no][0])\n",
    "\n",
    "                        coin_result = np.random.binomial(1,self.evolution_prob)\n",
    "\n",
    "                        if coin_result == 1:\n",
    "\n",
    "                            opt_menu = [0,1,2] # 0: Remove item from temp, 1: add item from final, 2: exchange\n",
    "\n",
    "                            if self.B_final_sets [pattern_no].intersection(temp[pattern_no]) == self.B_final_sets [pattern_no]:\n",
    "                                opt_menu.remove(1)\n",
    "\n",
    "                            if item in self.B_final_sets [pattern_no]:\n",
    "                                opt_menu.remove(0)\n",
    "\n",
    "                            if item in self.B_final_sets [pattern_no] or self.B_final_sets [pattern_no].intersection(temp[pattern_no]) == self.B_final_sets [pattern_no]:\n",
    "                                opt_menu.remove(2)\n",
    "\n",
    "                            if len(opt_menu) == 0: continue\n",
    "\n",
    "                            option = choice(opt_menu)\n",
    "\n",
    "                            if option == 0: # Remove item from temp\n",
    "\n",
    "                                items2remove[pattern_no].add(item)\n",
    "\n",
    "                            elif option == 1: # Add random item from final \n",
    "\n",
    "                                new_index = choice(list(self.B_final_sets [pattern_no].difference(temp[pattern_no])))\n",
    "                                items2add[pattern_no].add(new_index)   \n",
    "             \n",
    "                            elif option == 2: # exhcange\n",
    "                                \n",
    "                                new_index = choice(list(self.B_final_sets [pattern_no].difference(temp[pattern_no])))\n",
    "                                items2remove[pattern_no].add(item)\n",
    "                                items2add[pattern_no].add(new_index)\n",
    "\n",
    "                    temp[pattern_no].difference_update(items2remove[pattern_no])\n",
    "                    temp[pattern_no].update(items2add[pattern_no])\n",
    "\n",
    "                    if self.B_final_sets [pattern_no] == temp[pattern_no]:\n",
    "                                \n",
    "                        pattern_status[pattern_no] = 'final'\n",
    "\n",
    "                # Reoccuring\n",
    "                if self.type_of_drift[pattern_no] == 'reoccurring' and t % self.drift_indices[pattern_no][0] == 0:\n",
    "                    if pattern_status[pattern_no] == 'initial':\n",
    "\n",
    "                        temp[pattern_no] = self.B_final_sets[pattern_no]\n",
    "                        pattern_status[pattern_no] = 'final'\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        temp[pattern_no] = self.B_initial_sets[pattern_no]\n",
    "                        pattern_status[pattern_no] = 'initial'\n",
    "\n",
    "\n",
    "            self.Bs_lookup.append(temp)\n",
    "            self.pattern_statuses.append(deepcopy(pattern_status))\n",
    "\n",
    "        # Create Bs according to the index matrices\n",
    "\n",
    "        self.Bs = []\n",
    "\n",
    "        factor_template = np.zeros((self.J,self.no_of_concepts))\n",
    "\n",
    "        missing_indices = [[] for u in range(self.no_of_concepts)]\n",
    "        missing_indices_timestamps = [[] for u in range(self.no_of_concepts)]\n",
    "\n",
    "        new_indices = [[] for u in range(self.no_of_concepts)]\n",
    "        new_indices_timestamps = [[] for u in range(self.no_of_concepts)]\n",
    "\n",
    "        pattern_norms = {}\n",
    "\n",
    "        for t in range(self.K):\n",
    "\n",
    "            self.Bs.append(deepcopy(factor_template))\n",
    "\n",
    "            for pattern_no in range(self.no_of_concepts):\n",
    "\n",
    "                for index in self.Bs_lookup[t][pattern_no]:\n",
    "\n",
    "                    ## Randomly chosen values - uncomment following lines\n",
    "\n",
    "                    val = np.random.uniform(0.5, 1.0)\n",
    "                    while val < 0.5: val = np.random.uniform(0.5, 1.0)\n",
    "\n",
    "                    self.Bs[t][index,pattern_no] = val\n",
    "\n",
    "                    ## Bks that follow the PARAFAC2 constraint - uncomment following lines\n",
    "\n",
    "                # if t == 0:\n",
    "\n",
    "                #     n = len(self.Bs_lookup[t][pattern_no])\n",
    "                #     numbers = []\n",
    "\n",
    "                #     # Generate n random numbers between 0.5 and 1.0\n",
    "                #     for i in range(n):\n",
    "                #         numbers.append(np.random.uniform(0.5, 1.0))\n",
    "\n",
    "                #     pattern_norms[pattern_no] = np.sqrt(np.sum([num**2 for num in numbers]))\n",
    "                #     # print(f'be pattern{pattern_no}_norm:{pattern_norms[pattern_no]}')\n",
    "\n",
    "                #     for index in self.Bs_lookup[t][pattern_no]:\n",
    "                #         self.Bs[t][index,pattern_no] = numbers.pop()\n",
    "\n",
    "                # else:\n",
    "\n",
    "                #     n = len(self.Bs_lookup[t][pattern_no])\n",
    "                #     numbers = []\n",
    "\n",
    "                #     # Generate n random numbers between 0.5 and 1.0\n",
    "                #     for i in range(n):\n",
    "                #         numbers.append(np.random.uniform(0.5, 1.0))\n",
    "\n",
    "                #     my_norm = np.sqrt(np.sum([n**2 for n in numbers]))\n",
    "                #     numbers = [num*(pattern_norms[pattern_no]/my_norm) for num in numbers]\n",
    "                #     # print(f'aft my_norm:{np.sqrt(np.sum([n**2 for n in numbers]))}')\n",
    "\n",
    "                #     for index in self.Bs_lookup[t][pattern_no]:\n",
    "\n",
    "                #         self.Bs[t][index,pattern_no] = numbers.pop()\n",
    "\n",
    "                if self.type_of_drift[pattern_no] == 'incremental' and t > 0:\n",
    "\n",
    "                    # Find missing indices\n",
    "\n",
    "                    missing_indices[pattern_no].extend(list(self.Bs_lookup[t-1][pattern_no].difference(self.Bs_lookup[t][pattern_no])))\n",
    "                    missing_indices_timestamps[pattern_no].extend([t for _ in range(len(self.Bs_lookup[t-1][pattern_no].difference(self.Bs_lookup[t][pattern_no])))])\n",
    "\n",
    "                    # find new indices\n",
    "\n",
    "                    new_indices[pattern_no].extend(list(self.Bs_lookup[t][pattern_no].difference(self.Bs_lookup[t-1][pattern_no])))\n",
    "                    new_indices_timestamps[pattern_no].extend([t for _ in range(len(self.Bs_lookup[t][pattern_no].difference(self.Bs_lookup[t-1][pattern_no])))])\n",
    "\n",
    "                    # Apply sigmoid to missing indices\n",
    "\n",
    "                    for i in range(len(missing_indices[pattern_no])):\n",
    "\n",
    "                        self.Bs[t][missing_indices[pattern_no][i],pattern_no] = self.Bs[missing_indices_timestamps[pattern_no][i]-1][missing_indices[pattern_no][i],pattern_no] * self.sigmoid_(t,missing_indices_timestamps[pattern_no][i],-1*self.sigmoid_kurt)\n",
    "\n",
    "                    # Apply sigmoid to new indices\n",
    "\n",
    "                    for i in range(len(new_indices[pattern_no])):\n",
    "\n",
    "                        self.Bs[t][new_indices[pattern_no][i],pattern_no] *= self.sigmoid_(t-2,new_indices_timestamps[pattern_no][i],self.sigmoid_kurt)\n",
    "\n",
    "    def _generate_Cs_(self):\n",
    "        '''\n",
    "        Create and return C factor matrices.\n",
    "        '''\n",
    "\n",
    "        self.Cs = [deepcopy(np.eye(self.no_of_concepts))]\n",
    "\n",
    "        for concept_no in range(self.no_of_concepts):\n",
    "\n",
    "            init_val = choice([*range(5,20)])\n",
    "\n",
    "            self.Cs[0][concept_no,concept_no] *= init_val \n",
    "\n",
    "        for concept_no in range(self.no_of_concepts):\n",
    "            \n",
    "            if self.type_of_change[concept_no] == 'increasing':\n",
    "                self.Cs[0][concept_no,concept_no] = 0\n",
    "\n",
    "        change = []\n",
    "\n",
    "        for t in range(1,self.K):\n",
    "\n",
    "            self.Cs.append(deepcopy(self.Cs[-1]))\n",
    "\n",
    "            for pattern_no in range(self.no_of_concepts):\n",
    "\n",
    "                if self.type_of_change[pattern_no] == 'increasing' and self.change_indices[pattern_no][0] <= t:\n",
    "\n",
    "                    change = np.random.normal(loc=1.5,scale=0.5)\n",
    "                    while(change < 0): change = np.random.normal(loc=1.5,scale=0.5)\n",
    "\n",
    "                    self.Cs[t][pattern_no,pattern_no] += change\n",
    "\n",
    "                elif self.type_of_change[pattern_no] == 'decreasing' and self.change_indices[pattern_no][0] <= t:\n",
    "\n",
    "                    change = np.random.normal(loc=1.5,scale=0.5)\n",
    "                    while(change < 0): change = np.random.normal(loc=1.5,scale=0.5)\n",
    "\n",
    "                    self.Cs[t][pattern_no,pattern_no] -= change\n",
    "                \n",
    "                elif self.type_of_change[pattern_no] == 'periodical':\n",
    "\n",
    "                    if math.ceil(t/self.change_indices[pattern_no][0]) % 2 == 0:\n",
    "\n",
    "                        change = np.random.normal(loc=2.5,scale=0.5)\n",
    "                        while(change < 0): change = np.random.normal(loc=2.5,scale=0.5)\n",
    "\n",
    "                        self.Cs[t][pattern_no,pattern_no] += change\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        change = np.random.normal(loc=2.5,scale=0.5)\n",
    "                        while(change < 0): change = np.random.normal(loc=2.5,scale=0.5)\n",
    "\n",
    "                        self.Cs[t][pattern_no,pattern_no] -= change\n",
    "\n",
    "                elif self.type_of_change[pattern_no] == 'constant':\n",
    "\n",
    "                    change = np.random.normal(loc=0,scale=0.25)\n",
    "\n",
    "                    self.Cs[t][pattern_no,pattern_no] += change\n",
    "\n",
    "                self.Cs[t][np.where(np.diag(self.Cs[t]) <= 0)[0],np.where(np.diag(self.Cs[t]) <= 0)[0]] = 0.01 # Set non-positive values as 0.01!\n",
    "\n",
    "    def _add_noise_(self):\n",
    "        '''\n",
    "        Add noise to generated tensor.\n",
    "        '''\n",
    "\n",
    "        new_data = self.data\n",
    "\n",
    "        noisy_tensor = np.random.normal(loc=0,scale=1,size=new_data.shape)\n",
    "        noisy_tensor = self.noise_eta * tl.norm(self.data) * (noisy_tensor / tl.norm(noisy_tensor))\n",
    "        \n",
    "        self.data = new_data + noisy_tensor\n",
    "\n",
    "    def generate_data(self):\n",
    "        '''\n",
    "        Returns the generated data with given parameters.\n",
    "        '''\n",
    "    \n",
    "        if not hasattr(self,'data'):\n",
    "\n",
    "            # Generate factor matrices\n",
    "\n",
    "            self._generate_As_()\n",
    "\n",
    "            self._generate_Bs_()\n",
    "\n",
    "            self._generate_Cs_()\n",
    "\n",
    "            # Form tensor\n",
    "\n",
    "            X = tl.zeros((self.I,self.J,self.K))\n",
    "\n",
    "            for t in range(self.K):\n",
    "\n",
    "                X[...,t] = self.As @ self.Cs[t] @ self.Bs[t].T\n",
    "\n",
    "            self.data=X\n",
    "            self.noiseless_data = X\n",
    "\n",
    "            # Add random noise\n",
    "\n",
    "            self._add_noise_()\n",
    "\n",
    "            return self.data\n",
    "        \n",
    "        else:\n",
    "\n",
    "            if self.noise_eta != 0.0: self._add_noise_()\n",
    "\n",
    "            return self.data\n",
    "\n",
    "    def plot_As(self):\n",
    "\n",
    "        fig, axes = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "        im = axes.imshow(self.As)\n",
    "\n",
    "        axes.set_xticks([])\n",
    "        axes.set_yticks([])\n",
    "\n",
    "        fig.colorbar(im,ax=axes,pad=0.02)\n",
    "\n",
    "    def plot_Bs(self):     \n",
    "\n",
    "        fig, axes = plt.subplots(1,self.no_of_concepts)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        for i in range(self.no_of_concepts):\n",
    "\n",
    "            B_2_plot_gnd_truth = form_plotting_B(self.Bs,i,self.J,self.K)\n",
    "            im = sns.heatmap(B_2_plot_gnd_truth.T,ax=axes[i],cbar = False,cmap='viridis',rasterized=True)\n",
    "            axes[i].tick_params(left=False, bottom=True)\n",
    "            axes[i].patch.set_edgecolor('black')\n",
    "            axes[i].set_yticks([])\n",
    "            axes[i].patch.set_linewidth(1.5)\n",
    "            axes[i].set_xticks([4,9,14,19],labels=[5,10,15,20],fontsize=3.5)\n",
    "            axes[i].set_xlabel(r'time',fontsize=6)\n",
    "            axes[i].set_ylabel(r'words',fontsize=6)\n",
    "            axes[i].set_yticks([])\n",
    "            axes[i].set_title(f'{self.type_of_drift[i]}',pad=3.5,fontsize=6)\n",
    "    \n",
    "    def plot_Cs(self):\n",
    "\n",
    "        fig, axes = plt.subplots(1,1)\n",
    "\n",
    "        C_tensor = self.get_C_matrix()\n",
    "\n",
    "        axes.set_title(label='Columns of $C$',pad=3.5,fontsize=6)\n",
    "        axes.set_xticks([*range(1,self.K+1)])\n",
    "        axes.set_xlabel('time',fontsize=6)\n",
    "        axes.set_ylabel('strength',fontsize=6)\n",
    "\n",
    "        styles = ['solid','dotted','dashed','dashdot']\n",
    "        \n",
    "        for pattern_no in range(self.no_of_concepts):\n",
    "\n",
    "            axes.plot([*range(self.K)],C_tensor[:,pattern_no],label=f'$c_{pattern_no}$:{self.type_of_change[pattern_no]}',linewidth=0.5,linestyle=styles[pattern_no])\n",
    "        \n",
    "        axes.set_xticks([])\n",
    "        axes.set_xticklabels([])\n",
    "        axes.set_xticks([*range(0,self.K,2)])\n",
    "        axes.set_yticks([0,10,20])\n",
    "        axes.set_xticklabels([*range(1,self.K+1,2)],fontsize=3.5)\n",
    "\n",
    "        axes.legend(fontsize=4.5)\n",
    "        plt.show()\n",
    "\n",
    "    def dump_data(self,filename):\n",
    "        '''\n",
    "        Dump generator into files with pickle for easy readability.\n",
    "        '''\n",
    "\n",
    "        with open(filename, 'wb') as outp:\n",
    "            pickle.dump(self,outp,pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    def get_C_matrix(self):\n",
    "\n",
    "        new_Cs = tl.zeros((self.K,self.no_of_concepts))\n",
    "\n",
    "        for t in range(self.K):\n",
    "\n",
    "            new_Cs[t,:] = np.diag(self.Cs[t])\n",
    "\n",
    "        return new_Cs\n",
    "\n",
    "    def normalize_As(self):\n",
    "        '''\n",
    "        Column normalize each component.\n",
    "        '''\n",
    "\n",
    "        new_As = deepcopy(self.As)\n",
    "\n",
    "        for a_col in range(self.no_of_concepts):\n",
    "\n",
    "                new_As[:,a_col] /= np.linalg.norm(new_As[:,a_col])\n",
    "\n",
    "        return new_As\n",
    "\n",
    "    def normalize_Bs(self):\n",
    "        '''\n",
    "        Column normalize each component.\n",
    "        '''\n",
    "\n",
    "        new_Bs = deepcopy(self.Bs)\n",
    "\n",
    "        for r in range(self.no_of_concepts):\n",
    "\n",
    "            b_temp = new_Bs[0][:,r]\n",
    "\n",
    "            for k in range(1,len(new_Bs)):\n",
    "\n",
    "                b_temp = np.concatenate((b_temp,new_Bs[k][:,r]))\n",
    "\n",
    "            for k in range(len(new_Bs)):\n",
    "\n",
    "                new_Bs[k][:,r] = new_Bs[k][:,r] / np.linalg.norm(b_temp)\n",
    "\n",
    "        return new_Bs\n",
    "\n",
    "    def normalize_Cs(self,return_one_matrix=False):\n",
    "        '''\n",
    "        Column normalize each component.\n",
    "        '''\n",
    "\n",
    "        if return_one_matrix == False:\n",
    "\n",
    "            new_Cs = deepcopy(self.Cs)\n",
    "\n",
    "            for pattern_no in range(self.no_of_concepts):\n",
    "\n",
    "                # Find norm of column of vector\n",
    "\n",
    "                c_vec = np.array([new_Cs[0][pattern_no,pattern_no]])\n",
    "\n",
    "                for t in range(self.K):\n",
    "\n",
    "                    c_vec = np.append(c_vec,new_Cs[t][pattern_no,pattern_no])\n",
    "\n",
    "                c_norm = np.linalg.norm(c_vec)\n",
    "\n",
    "                # Divide each entry by the norm\n",
    "\n",
    "                for t in range(self.K):\n",
    "\n",
    "                    new_Cs[t][pattern_no,pattern_no] = new_Cs[t][pattern_no,pattern_no] / c_norm\n",
    "\n",
    "        else:\n",
    "\n",
    "            new_Cs = tl.zeros((self.K,self.no_of_concepts))\n",
    "\n",
    "            for t in range(self.K):\n",
    "\n",
    "                new_Cs[t,:] = np.diag(self.Cs[t]) / tl.norm(np.diag(self.Cs[t]))\n",
    "\n",
    "        return new_Cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matcouply custom penalty class\n",
    "\n",
    "class TemporalSmoothnessPenalty(MatricesPenalty):\n",
    "    def __init__(self, smoothness_l, aux_init=\"random_uniform\", dual_init=\"random_uniform\"):\n",
    "        super().__init__(aux_init=aux_init, dual_init=dual_init)\n",
    "        self.smoothness_l = smoothness_l\n",
    "\n",
    "    @copy_ancestor_docstring\n",
    "    def factor_matrices_update(self, factor_matrices, feasibility_penalties, auxes):\n",
    "        \n",
    "        # factor_matrices: factor + mus\n",
    "        # feasability_penalties: rhos\n",
    "        # auxes: -||-\n",
    "\n",
    "        B_is = factor_matrices\n",
    "        rhos = feasibility_penalties\n",
    "\n",
    "        rhs = [rhos[i] * factor_matrices[i] for i in range(len(B_is))]\n",
    "\n",
    "        # Construct matrix A to peform gaussian elimination on\n",
    "\n",
    "        A = np.zeros((len(B_is),len(B_is)))\n",
    "\n",
    "        for i in range(len(B_is)):\n",
    "            for j in range(len(B_is)):\n",
    "                if i == j: A[i,j] = 4*self.smoothness_l + rhos[i]\n",
    "                elif i == j-1 or i == j+1: A[i,j] = -2*self.smoothness_l\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "        A[0,0] -= 2*self.smoothness_l\n",
    "        A[len(B_is)-1,len(B_is)-1] -= 2*self.smoothness_l\n",
    "\n",
    "        # Peform GE\n",
    "\n",
    "        for k in range(1,A.shape[-1]):\n",
    "            m = A[k,k-1]/A[k-1,k-1]\n",
    "\n",
    "            A[k,:] = A[k,:] - m * A[k-1,:]\n",
    "            rhs[k] = rhs[k] - m * rhs[k-1] # Also update the respective rhs!\n",
    "\n",
    "        # Back-substitution\n",
    "\n",
    "        new_ZBks = [np.empty_like(B_is[i]) for i in range(len(B_is))]\n",
    "\n",
    "        new_ZBks[-1] = rhs[-1]/A[-1,-1]\n",
    "        q = new_ZBks[-1]\n",
    "\n",
    "        for i in range(A.shape[-1]-2,-1,-1):\n",
    "            q = (rhs[i] - A[i,i+1] * q) / A[i,i]\n",
    "            new_ZBks[i] = q \n",
    "\n",
    "        return new_ZBks\n",
    "\n",
    "    def penalty(self, x):\n",
    "        penalty = 0\n",
    "        for x1, x2 in zip(x[:-1], x[1:]):\n",
    "            penalty += np.sum((x1-x2)**2)   \n",
    "        return self.smoothness_l * penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking degeneracy\n",
    "\n",
    "def check_degenerate(factors,threshold=-0.85):\n",
    "    '''\n",
    "    Check solution for degenerecy (just a wrapper for tlviz degeneracy score).\n",
    "    '''\n",
    "\n",
    "    A = factors[0]\n",
    "    B = factors[1]\n",
    "    D = factors[2]\n",
    "\n",
    "    new_B = np.zeros((len(B)*B[0].shape[0],B[0].shape[-1]))\n",
    "\n",
    "    for r in range(B[0].shape[-1]):\n",
    "        \n",
    "        b_temp = B[0][:,r]\n",
    "\n",
    "        for k in range(1,len(B)):\n",
    "\n",
    "            b_temp = np.concatenate((b_temp,B[k][:,r]))\n",
    "\n",
    "        new_B[:,r] = b_temp\n",
    "\n",
    "    decomp = CPTensor((np.array([1.0,1.0,1.0,1.0]),(A,new_B,D)))\n",
    "\n",
    "    if degeneracy_score(decomp) < threshold: return True\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for FMS computation\n",
    "\n",
    "def fms(decomposition1,decomposition2,absolute_value=False):\n",
    "    '''\n",
    "    Receive two decompositions and compute the factor match score using the factor_match_score function from tlviz.\n",
    "    '''\n",
    "\n",
    "    decomp1 = deepcopy(decomposition1)\n",
    "    decomp2 = deepcopy(decomposition2)\n",
    "\n",
    "    # Create new matrix B such that each column is the concatenation of the columns of the matrices in decompositions\n",
    "\n",
    "    new_B1 = np.zeros((decomp1[1][0].shape[0]*len(decomp1[1]),decomp1[1][0].shape[-1]))\n",
    "\n",
    "    for r in range(decomp1[1][0].shape[-1]):\n",
    "\n",
    "        b_temp = decomp1[1][0][:,r]\n",
    "\n",
    "        for k in range(1,len(decomp1[1])):\n",
    "\n",
    "            b_temp = np.concatenate((b_temp,decomp1[1][k][:,r]))\n",
    "\n",
    "        new_B1[:,r] = b_temp\n",
    "\n",
    "    new_B2 = np.zeros((decomp2[1][0].shape[0]*len(decomp2[1]),decomp2[1][0].shape[-1]))\n",
    "\n",
    "    for r in range(decomp2[1][0].shape[-1]):\n",
    "\n",
    "        b_temp = decomp2[1][0][:,r]\n",
    "\n",
    "        for k in range(1,len(decomp2[1])):\n",
    "\n",
    "            b_temp = np.concatenate((b_temp,decomp2[1][k][:,r]))\n",
    "\n",
    "        new_B2[:,r] = b_temp\n",
    "\n",
    "    cp_tensor1 = (tl.tensor([1.0,1.0,1.0,1.0]),(decomp1[0],new_B1,decomp1[2]))\n",
    "    cp_tensor2 = (tl.tensor([1.0,1.0,1.0,1.0]),(decomp2[0],new_B2,decomp2[2]))\n",
    "\n",
    "    return factor_match_score(cp_tensor1,cp_tensor2,absolute_value=absolute_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting functions\n",
    "\n",
    "def get_plot_mask(gnd_B,est_B,gnd_A,est_A):\n",
    "    '''\n",
    "    Returns a matrix that matches each column vector\n",
    "    to components of the ground truth.\n",
    "    '''\n",
    "\n",
    "    decomp_rank = est_B[0].shape[1]\n",
    "\n",
    "    # Create masking matrix\n",
    "    plot_mask = [-1 for u in range(decomp_rank)]\n",
    "\n",
    "    for factor_no in range(decomp_rank):\n",
    "\n",
    "        cur_b_factor = form_plotting_B(np.absolute(est_B),factor_no,est_B[0].shape[0],len(est_B))\n",
    "        cur_b_gnd_factor = form_plotting_B(gnd_B,0,est_B[0].shape[0],len(est_B))\n",
    "\n",
    "        best_match = 0\n",
    "        best_dist = spatial.distance.cosine(np.absolute(cur_b_factor.flatten()),cur_b_gnd_factor.flatten()) + spatial.distance.cosine(np.absolute(est_A[:,factor_no]),gnd_A[:,0])\n",
    "\n",
    "        for i in range(1,decomp_rank):\n",
    "\n",
    "            cur_b_gnd_factor = form_plotting_B(gnd_B,i,est_B[0].shape[0],len(est_B))\n",
    "\n",
    "            if spatial.distance.cosine(np.absolute(cur_b_factor.flatten()),cur_b_gnd_factor.flatten()) + spatial.distance.cosine(np.absolute(est_A[:,factor_no]),gnd_A[:,i]) <= best_dist:\n",
    "\n",
    "                best_match = i\n",
    "                best_dist = spatial.distance.cosine(np.absolute(cur_b_factor.flatten()),cur_b_gnd_factor.flatten()) + spatial.distance.cosine(np.absolute(est_A[:,factor_no]),gnd_A[:,i])\n",
    "\n",
    "        plot_mask[factor_no] = best_match\n",
    "\n",
    "    return plot_mask\n",
    "\n",
    "def form_plotting_B(B_list,pattern_no,J,K):\n",
    "    '''\n",
    "    Takes as input a list of B factors and return a matrix containing \n",
    "    the pattern_no-th column of each factor matrix.\n",
    "    '''\n",
    "\n",
    "    matrix2return = np.zeros((K,J))\n",
    "\n",
    "    for k in range(K):\n",
    "\n",
    "        matrix2return[k,:] = B_list[k][:,pattern_no].T\n",
    "\n",
    "    return matrix2return\n",
    "\n",
    "def plot_Bs(data_generator,factor_list):\n",
    "    '''\n",
    "    Plot groudn truth and A and D factors alongside each other.\n",
    "    titles contains a list of titles per column\n",
    "\n",
    "    If any of the above are not given, plot what is available each time.\n",
    "    '''\n",
    "\n",
    "    fig, axes = plt.subplots(data_generator.no_of_concepts,1+len(factor_list),figsize=(12,6))\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "\n",
    "    # Create a list with FMS scores\n",
    "    fms_scores = []\n",
    "\n",
    "    for factor_no in range(len(factor_list)):\n",
    "\n",
    "        fms_scores.append(fms(decomposition1=(data_generator.get_C_matrix(),data_generator.Bs,data_generator.As),decomposition2=factor_list[factor_no],absolute_value=True))\n",
    "\n",
    "    # Normalize ground truth factors\n",
    "    gnd_Bs = deepcopy(data_generator.normalize_Bs())\n",
    "    gnd_A = deepcopy(data_generator.normalize_As())\n",
    "\n",
    "    B_2_plot_gnd_truth = []\n",
    "\n",
    "    for pattern_no in range(data_generator.no_of_concepts):\n",
    "\n",
    "        # Create ground truth matrix\n",
    "\n",
    "        B_2_plot_gnd_truth.append(form_plotting_B(gnd_Bs,pattern_no,data_generator.J,data_generator.K))\n",
    "\n",
    "        im = axes[pattern_no][0].imshow(B_2_plot_gnd_truth[-1],vmin=-0.4,vmax=1.0,cmap='viridis')\n",
    "        axes[pattern_no][0].set_xticks([])\n",
    "        axes[pattern_no][0].set_yticks([])\n",
    "        axes[pattern_no][0].yaxis.set_label_position(\"left\")\n",
    "        axes[pattern_no][0].set_ylabel(f'Pattern {pattern_no}')\n",
    "        if pattern_no == 0: axes[pattern_no][0].set_title('Ground truth')\n",
    "\n",
    "    if len(factor_list) >= 1: # More factors are given as input\n",
    "\n",
    "        for l in range(len(factor_list)):\n",
    "\n",
    "            est_A = deepcopy(factor_list[l][2])\n",
    "            est_B = deepcopy(factor_list[l][1])\n",
    "            est_D = deepcopy(factor_list[l][0])\n",
    "\n",
    "            for r in range(data_generator.no_of_concepts):\n",
    "\n",
    "                est_A[:,r] = est_A[:,r] / tl.norm(est_A[:,r])\n",
    "\n",
    "                b_temp = est_B[0][:,r]\n",
    "\n",
    "                for k in range(1,len(gnd_Bs)):\n",
    "\n",
    "                    b_temp = np.concatenate((b_temp,est_B[k][:,r]))\n",
    "\n",
    "                for k in range(len(gnd_Bs)):\n",
    "\n",
    "                    est_B[k][:,r] = est_B[k][:,r] / np.linalg.norm(b_temp)\n",
    "\n",
    "            plot_mask = get_plot_mask(gnd_Bs,est_B,gnd_A,est_A)\n",
    "\n",
    "            for pattern_no in range(data_generator.no_of_concepts):\n",
    "\n",
    "                parafac2_estimate_B = form_plotting_B(est_B,pattern_no,data_generator.J,data_generator.K)\n",
    "\n",
    "                im = axes[plot_mask[pattern_no]][l+1].imshow(parafac2_estimate_B,vmin=-0.4,vmax=0.4,cmap='viridis')\n",
    "                axes[plot_mask[pattern_no]][l+1].set_xticks([])\n",
    "                axes[plot_mask[pattern_no]][l+1].set_yticks([])\n",
    "                if plot_mask[pattern_no] == 0: axes[plot_mask[pattern_no]][l+1].set_title(f'FMS: {fms_scores[l]:.2f}')\n",
    "\n",
    "def plot_A(data_generator,factor_list):\n",
    "    '''\n",
    "    Plot groudn truth and A factors alongside each other.\n",
    "    factor_list is a list containing factors in this specific order:\n",
    "    titles contains a list of titles per column\n",
    "\n",
    "    If any of the above are not given, plot what is available each time.\n",
    "    '''\n",
    "\n",
    "    fig, axes = plt.subplots(data_generator.no_of_concepts,len(factor_list),figsize=(12,6))\n",
    "\n",
    "    # Create a list with FMS scores\n",
    "    fms_scores = []\n",
    "\n",
    "    for factor_no in range(len(factor_list)):\n",
    "\n",
    "        fms_scores.append(fms(decomposition1=(data_generator.get_C_matrix(),data_generator.Bs,data_generator.As),decomposition2=factor_list[factor_no],absolute_value=True))\n",
    "\n",
    "    # Normalize ground truth factors\n",
    "\n",
    "    gnd_A = deepcopy(data_generator.normalize_As())\n",
    "    gnd_Bs = deepcopy(data_generator.normalize_Bs())\n",
    "\n",
    "    # Iterate over given factors\n",
    "\n",
    "    for l in range(len(factor_list)):\n",
    "\n",
    "        est_A = deepcopy(factor_list[l][2])\n",
    "        est_B = deepcopy(factor_list[l][1])\n",
    "\n",
    "        for r in range(data_generator.no_of_concepts):\n",
    "\n",
    "            est_A[:,r] = est_A[:,r] / tl.norm(est_A[:,r])\n",
    "\n",
    "            b_temp = est_B[0][:,r]\n",
    "\n",
    "            for k in range(1,len(gnd_Bs)):\n",
    "\n",
    "                b_temp = np.concatenate((b_temp,est_B[k][:,r]))\n",
    "\n",
    "            for k in range(len(gnd_Bs)):\n",
    "\n",
    "                est_B[k][:,r] = est_B[k][:,r] / np.linalg.norm(b_temp)\n",
    "\n",
    "        plot_mask = get_plot_mask(gnd_Bs,est_B,gnd_A,est_A)\n",
    "\n",
    "        for pattern_no in range(data_generator.no_of_concepts):\n",
    "\n",
    "            # Plot ground truth (gnd_A)\n",
    "\n",
    "            try: # This is a hack for the case we want to plot just one set of factors\n",
    "\n",
    "                im = axes[pattern_no][l].plot(gnd_A[:,pattern_no],label='gnd truth',color='tab:blue',alpha=0.4)\n",
    "\n",
    "                # Plot factor (est_A)\n",
    "                axes[plot_mask[pattern_no]][l].plot(est_A[:,pattern_no],label='factor',color='tab:blue')\n",
    "\n",
    "                # Add plotting settings\n",
    "                if l == len(factor_list)-1 and pattern_no == data_generator.no_of_concepts-1: \n",
    "                    axes[pattern_no][l].legend(prop={'size': 7})\n",
    "                axes[pattern_no][l].set_ylabel(f'Pattern {pattern_no}')\n",
    "                axes[pattern_no][l].set_xticks([])\n",
    "                if pattern_no == 0: axes[pattern_no][l].set_title(f'FMS: {fms_scores[l]:.2f}')\n",
    "\n",
    "            except:\n",
    "                \n",
    "                im = axes[pattern_no].plot(gnd_A[:,pattern_no],label='gnd truth',color='tab:blue',alpha=0.4)\n",
    "\n",
    "                # Plot factor (est_A)\n",
    "                axes[plot_mask[pattern_no]].plot(est_A[:,pattern_no],label='factor',color='tab:blue')\n",
    "\n",
    "                # Add plotting settings\n",
    "                if l == len(factor_list)-1 and pattern_no == data_generator.no_of_concepts-1: \n",
    "                    axes[pattern_no].legend(prop={'size': 7})\n",
    "                axes[pattern_no][l].set_ylabel(f'Pattern {pattern_no}')\n",
    "                axes[pattern_no].set_xticks([])\n",
    "                if pattern_no == 0: axes[pattern_no][l].set_title(f'FMS: {fms_scores[l]:.2f}')\n",
    "\n",
    "def plot_C(data_generator,factor_list):\n",
    "    '''\n",
    "    Plot groudn truth and A factors alongside each other.\n",
    "    factor_list is a list containing factors in this specific order:\n",
    "    titles contains a list of titles per column\n",
    "\n",
    "    If any of the above are not given, plot what is available each time.\n",
    "    '''\n",
    "    # Determine size of plot\n",
    "\n",
    "    fig, axes = plt.subplots(data_generator.no_of_concepts,len(factor_list),figsize=(12,6))\n",
    "\n",
    "    # Create a list with FMS scores\n",
    "    fms_scores = []\n",
    "\n",
    "    for factor_no in range(len(factor_list)):\n",
    "\n",
    "        fms_scores.append(fms(decomposition1=(data_generator.get_C_matrix(),data_generator.Bs,data_generator.As),decomposition2=factor_list[factor_no],absolute_value=True))\n",
    "\n",
    "    # Normalize ground truth factors\n",
    "\n",
    "    gnd_A = deepcopy(data_generator.normalize_As())\n",
    "    gnd_Bs = deepcopy(data_generator.normalize_Bs())\n",
    "    gnd_Cs = deepcopy(data_generator.normalize_Cs(return_one_matrix=True))\n",
    "\n",
    "    # Iterate over given factors\n",
    "\n",
    "    for l in range(len(factor_list)):\n",
    "\n",
    "        est_A = deepcopy(factor_list[l][2])\n",
    "        est_B = deepcopy(factor_list[l][1])\n",
    "        est_C = deepcopy(factor_list[l][0])\n",
    "\n",
    "        for r in range(data_generator.no_of_concepts):\n",
    "\n",
    "            est_A[:,r] = est_A[:,r] / tl.norm(est_A[:,r])\n",
    "\n",
    "            b_temp = est_B[0][:,r]\n",
    "\n",
    "            for k in range(1,len(gnd_Bs)):\n",
    "\n",
    "                b_temp = np.concatenate((b_temp,est_B[k][:,r]))\n",
    "\n",
    "            for k in range(len(gnd_Bs)):\n",
    "\n",
    "                est_C[k,:] = est_C[k,:] / tl.norm(est_C[k,:])\n",
    "\n",
    "                est_B[k][:,r] = est_B[k][:,r] / np.linalg.norm(b_temp)\n",
    "\n",
    "        plot_mask = get_plot_mask(gnd_Bs,est_B,gnd_A,est_A)\n",
    "\n",
    "        for pattern_no in range(data_generator.no_of_concepts):\n",
    "\n",
    "            try:\n",
    "\n",
    "                # Plot ground truth (gnd_A)\n",
    "                im = axes[pattern_no][l].plot(gnd_Cs[:,pattern_no],label='gnd truth',color='tab:green',alpha=0.4)\n",
    "\n",
    "                # Plot factor (est_A)\n",
    "                axes[plot_mask[pattern_no]][l].plot(est_C[:,pattern_no],label='factor',color='tab:green')\n",
    "\n",
    "                # Add plotting settings\n",
    "                if l == len(factor_list)-1 and pattern_no == data_generator.no_of_concepts-1: \n",
    "                    axes[pattern_no][l].legend(prop={'size': 7})\n",
    "                axes[pattern_no][l].set_ylabel(f'Pattern {pattern_no}')\n",
    "                axes[pattern_no][l].set_xticks([])\n",
    "                if pattern_no == 0: axes[pattern_no][l].set_title(f'FMS: {fms_scores[l]:.2f}')\n",
    "                \n",
    "            except:\n",
    "\n",
    "                # Plot ground truth (gnd_A)\n",
    "                im = axes[pattern_no].plot(gnd_Cs[:,pattern_no],label='gnd truth',color='tab:green',alpha=0.4)\n",
    "\n",
    "                # Plot factor (est_A)\n",
    "                axes[plot_mask[pattern_no]].plot(est_C[:,pattern_no],label='factor',color='tab:green')\n",
    "                # Add plotting settings\n",
    "                if l == len(factor_list)-1 and pattern_no == data_generator.no_of_concepts-1: \n",
    "                    axes[pattern_no].legend(prop={'size': 7})\n",
    "                axes[pattern_no].set_ylabel(f'Pattern {pattern_no}')\n",
    "                axes[pattern_no].set_xticks([])\n",
    "                if pattern_no == 0: axes[pattern_no][l].set_title(f'FMS: {fms_scores[l]:.2f}')\n",
    "\n",
    "def plot_results(data_generator,factor_list):\n",
    "    '''\n",
    "    Plots results of given factors along with the\n",
    "    ground truth. Takes care of component matching.\n",
    "    '''\n",
    "\n",
    "    # Plot Bs\n",
    "    plot_Bs(data_generator,factor_list)\n",
    "\n",
    "    # Plot As\n",
    "    plot_A(data_generator,factor_list)\n",
    "\n",
    "    # Plot Cs\n",
    "    plot_C(data_generator,factor_list)\n",
    "\n",
    "def plot_data(data):\n",
    "    '''\n",
    "    Plots all frontal slices (X::k) of the data_generator.data.\n",
    "    '''\n",
    "\n",
    "    K = data.shape[-1]\n",
    "\n",
    "    mosaic_lists = []\n",
    "    mosaic_lists.append([*range(math.ceil(K/2))])\n",
    "    mosaic_lists.append([*range(math.ceil(K/2),K)])\n",
    "\n",
    "    # Plot frontal slices of data\n",
    "    fig, axs = plt.subplot_mosaic(mosaic_lists,figsize=(12,6))\n",
    "\n",
    "    for k in range(K):\n",
    "        im = axs[k].imshow(data[:,:,k])\n",
    "        axs[k].set_title(f'Frontal slice {k}',fontsize=6)\n",
    "\n",
    "        # Remove ticks\n",
    "        axs[k].set_xticks([])\n",
    "        axs[k].set_yticks([])\n",
    "\n",
    "    # Add new axis for colorbar\n",
    "    cax = fig.add_axes([1, 0.15, 0.015, 0.7])\n",
    "    fig.colorbar(im, cax=cax)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_convergence(diagnostics_per_init,factors_per_init,zoom_in_to_first_n=50):\n",
    "    '''\n",
    "    Plot convergence of all initializations in the following format:\n",
    "\n",
    "    rel_sse | parafac2 constraint feasiblity gap\n",
    "    -----------------------------------------------\n",
    "    total_loss | temporal smoothness feasibility gap\n",
    "\n",
    "    Degenerate cases are not plotted.\n",
    "    '''\n",
    "\n",
    "    inits2ignore = [False] * len(factors_per_init)\n",
    "    \n",
    "    for init_no in range(len(factors_per_init)):\n",
    "        \n",
    "        if check_degenerate(factors_per_init[init_no]) == True:\n",
    "            \n",
    "            inits2ignore[init_no] = True\n",
    "            print(f'Initialization {init_no} is degenerate and will not be plotted.')\n",
    "\n",
    "    fig, axs = plt.subplot_mosaic([['rec_errors','parafac2_feasibility'],['reg_loss','smoothness_feasiblity']],figsize=(12,6))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    max_iters = max([diag.n_iter for diag in diagnostics_per_init])\n",
    "\n",
    "    all_min_cur_error = []\n",
    "    all_min_cur_parafac2_feasibility = []\n",
    "    all_min_cur_reg_loss = []\n",
    "    all_min_cur_smoothness_feasibility = []\n",
    "\n",
    "    all_max_cur_error = []\n",
    "    all_max_cur_parafac2_feasibility = []\n",
    "    all_max_cur_reg_loss = []\n",
    "    all_max_cur_smoothness_feasibility = []\n",
    "\n",
    "    all_median_cur_error = []\n",
    "    all_median_cur_parafac2_feasibility = []\n",
    "    all_median_cur_reg_loss = []\n",
    "    all_median_cur_smoothness_feasibility = []\n",
    "\n",
    "    for iter_no in range(max_iters):\n",
    "\n",
    "        # Form a list of all diagnostics for this initialization at the current iteration\n",
    "\n",
    "        cur_rer_errors = []\n",
    "        cur_parafac2_feasibility = []\n",
    "        cur_reg_loss = []\n",
    "        cur_smoothness_feasibility = []\n",
    "\n",
    "        for init_no in range(len(factors_per_init)):\n",
    "\n",
    "            if inits2ignore[init_no] == False and iter_no <= diagnostics_per_init[init_no].n_iter:\n",
    "\n",
    "                cur_rer_errors.append(diagnostics_per_init[init_no].rec_errors[iter_no])\n",
    "                # cur_rer_errors.append(diagnostics_per_init[init_no].un_rec_errors[iter_no])\n",
    "                cur_parafac2_feasibility.append(diagnostics_per_init[init_no].feasibility_gaps[iter_no][1][0])\n",
    "                try:\n",
    "                    cur_smoothness_feasibility.append(diagnostics_per_init[init_no].feasibility_gaps[iter_no][1][1])\n",
    "                except:\n",
    "                    pass\n",
    "                cur_reg_loss.append(diagnostics_per_init[init_no].regularized_loss[iter_no])\n",
    "\n",
    "        all_min_cur_error.append(min(cur_rer_errors))\n",
    "        all_max_cur_error.append(max(cur_rer_errors))\n",
    "        all_median_cur_error.append(np.median(cur_rer_errors))\n",
    "\n",
    "        all_min_cur_parafac2_feasibility.append(min(cur_parafac2_feasibility))\n",
    "        all_max_cur_parafac2_feasibility.append(max(cur_parafac2_feasibility))\n",
    "        all_median_cur_parafac2_feasibility.append(np.median(cur_parafac2_feasibility))\n",
    "\n",
    "        all_min_cur_reg_loss.append(min(cur_reg_loss))\n",
    "        all_max_cur_reg_loss.append(max(cur_reg_loss))\n",
    "        all_median_cur_reg_loss.append(np.median(cur_reg_loss))\n",
    "\n",
    "        try:\n",
    "            all_min_cur_smoothness_feasibility.append(min(cur_smoothness_feasibility))\n",
    "            all_max_cur_smoothness_feasibility.append(max(cur_smoothness_feasibility))\n",
    "            all_median_cur_smoothness_feasibility.append(np.median(cur_smoothness_feasibility))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Plot the area between min and max errors and the median error\n",
    "    axs['rec_errors'].fill_between(range(max_iters),all_min_cur_error,all_max_cur_error,color='tab:blue',alpha=0.2)\n",
    "    axs['rec_errors'].plot(range(max_iters),all_median_cur_error,color='tab:blue',label='rec_errors')\n",
    "    axs['rec_errors'].set_title('Relative SSE')\n",
    "\n",
    "    # Plot the area between min and max parafac2 feasibility and the median parafac2 feasibility\n",
    "    try:\n",
    "        axs['parafac2_feasibility'].fill_between(range(max_iters),all_min_cur_parafac2_feasibility,all_max_cur_parafac2_feasibility,color='tab:orange',alpha=0.2)\n",
    "        axs['parafac2_feasibility'].plot(range(max_iters),all_median_cur_parafac2_feasibility,color='tab:orange',label='parafac2_feasibility')\n",
    "        axs['parafac2_feasibility'].set_title('Parafac2 feasibility')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Plot the area between min and max reg loss and the median reg loss\n",
    "    axs['reg_loss'].fill_between(range(max_iters),all_min_cur_reg_loss,all_max_cur_reg_loss,color='tab:green',alpha=0.2)\n",
    "    axs['reg_loss'].plot(range(max_iters),all_median_cur_reg_loss,color='tab:green',label='reg_loss')\n",
    "    axs['reg_loss'].set_title('Total loss')\n",
    "\n",
    "    # Plot the area between min and max smoothness feasibility and the median smoothness feasibility\n",
    "    try:\n",
    "        axs['smoothness_feasiblity'].fill_between(range(max_iters),all_min_cur_smoothness_feasibility,all_max_cur_smoothness_feasibility,color='tab:red',alpha=0.2)\n",
    "        axs['smoothness_feasiblity'].plot(range(max_iters),all_median_cur_smoothness_feasibility,color='tab:red',label='smoothness_feasiblity')\n",
    "        axs['smoothness_feasiblity'].set_title('Smoothness feasibility')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    zoomed_in_rec_error = fig.add_axes([0.285,0.765,0.2,0.2])\n",
    "\n",
    "    zoomed_in_rec_error.fill_between(range(max_iters)[:zoom_in_to_first_n],all_min_cur_error[:zoom_in_to_first_n],all_max_cur_error[:zoom_in_to_first_n],color='tab:blue',alpha=0.2)\n",
    "    zoomed_in_rec_error.plot(range(max_iters)[:zoom_in_to_first_n],all_median_cur_error[:zoom_in_to_first_n],color='tab:blue',label='rec_errors')\n",
    "    zoomed_in_rec_error.set_yticks([0.2,0.4,0.6,0.8])\n",
    "\n",
    "    try:\n",
    "        zoomed_in_parafac2_feasibility = fig.add_axes([0.778,0.765,0.2,0.2])\n",
    "        zoomed_in_parafac2_feasibility.fill_between(range(max_iters)[:zoom_in_to_first_n],all_min_cur_parafac2_feasibility[:zoom_in_to_first_n],all_max_cur_parafac2_feasibility[:zoom_in_to_first_n],color='tab:orange',alpha=0.2)\n",
    "        zoomed_in_parafac2_feasibility.plot(range(max_iters)[:zoom_in_to_first_n],all_median_cur_parafac2_feasibility[:zoom_in_to_first_n],color='tab:orange',label='parafac2_feasibility')\n",
    "        zoomed_in_parafac2_feasibility.set_yticks([0.2,0.4,0.6,0.8])\n",
    "        zoomed_in_parafac2_feasibility.set_yscale('log')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    zoomed_in_reg_loss = fig.add_axes([0.285,0.278,0.2,0.2])\n",
    "    zoomed_in_reg_loss.fill_between(range(max_iters)[:zoom_in_to_first_n],all_min_cur_reg_loss[:zoom_in_to_first_n],all_max_cur_reg_loss[:zoom_in_to_first_n],color='tab:green',alpha=0.2)\n",
    "    zoomed_in_reg_loss.plot(range(max_iters)[:zoom_in_to_first_n],all_median_cur_reg_loss[:zoom_in_to_first_n],color='tab:green',label='reg_loss')\n",
    "    zoomed_in_reg_loss.set_yscale('log')\n",
    "\n",
    "    try:\n",
    "        zoomed_in_smoothness_feasiblity = fig.add_axes([0.778,0.278,0.2,0.2])\n",
    "        zoomed_in_smoothness_feasiblity.fill_between(range(max_iters)[:zoom_in_to_first_n],all_min_cur_smoothness_feasibility[:zoom_in_to_first_n],all_max_cur_smoothness_feasibility[:zoom_in_to_first_n],color='tab:red',alpha=0.2)\n",
    "        zoomed_in_smoothness_feasiblity.plot(range(max_iters)[:zoom_in_to_first_n],all_median_cur_smoothness_feasibility[:zoom_in_to_first_n],color='tab:red',label='smoothness_feasiblity')\n",
    "        zoomed_in_smoothness_feasiblity.set_yscale('log')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Create some synthetic data with desired properties\n",
    "\n",
    "c1 = np.random.randint(low=2,high=18)\n",
    "c2 = np.random.randint(low=2,high=18)\n",
    "c3 = np.random.randint(low=2,high=18)\n",
    "c4 = np.random.randint(low=2,high=18)\n",
    "\n",
    "my_generator = data_generator(no_of_concepts=4,\n",
    "type_of_drift=['reoccurring','gradual','incremental','sudden'],\n",
    "type_of_change = ['constant','decreasing','periodical','increasing'],\n",
    "I=40,\n",
    "J=30,\n",
    "K=20,\n",
    "B_internal_overlap=25,\n",
    "B_external_overlap=0,\n",
    "sigmoid_kurt=1,\n",
    "evolution_prob=0.3,\n",
    "drift_indices=[[c1],[c2],[c3],[c3]],\n",
    "change_indices=[[4],[12],[4],[6]],\n",
    "noise_eta=0.25,\n",
    "B_external_overlap_when='start',\n",
    "A_negative=True,\n",
    ")\n",
    "\n",
    "data = my_generator.generate_data()\n",
    "my_generator.plot_As()\n",
    "my_generator.plot_Bs()\n",
    "my_generator.plot_Cs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Plot the data\n",
    "\n",
    "plot_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Run multiple initialization of tPARAFAC2\n",
    "\n",
    "from matcouply.penalties import NonNegativity,Parafac2\n",
    "import matcouply.decomposition as decomposition\n",
    "\n",
    "no_of_inits = 20\n",
    "n_iter_max = 1000\n",
    "\n",
    "factors_per_init = []\n",
    "diagnostics_per_init = []\n",
    "\n",
    "for init in range(no_of_inits):\n",
    "\n",
    "    regs = [[ NonNegativity() ],\n",
    "        [ Parafac2(),TemporalSmoothnessPenalty(smoothness_l=100) ],\n",
    "        []]\n",
    "\n",
    "    (weights,(D,B,A)),diagnostics = decomposition.cmf_aoadmm(\n",
    "        matrices=[tl.tensor(data[:,:,u].T) for u in range(data.shape[-1])],\n",
    "        rank=4,\n",
    "        return_errors = True,\n",
    "        n_iter_max=n_iter_max,\n",
    "        l2_penalty=[2*10e-2,0,2*10e-2],\n",
    "        regs=regs,\n",
    "        verbose=0,\n",
    "        tol=1e-3,\n",
    "        inner_n_iter_max=1,\n",
    "        absolute_tol=1e-3,\n",
    "        feasibility_tol=1e-4,\n",
    "        inner_tol=1e-4,\n",
    "    )\n",
    "\n",
    "    factors_per_init.append([D,B,A])\n",
    "    diagnostics_per_init.append(diagnostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Find best performing run (least loss)\n",
    "\n",
    "least_loss = np.Inf\n",
    "least_loss_run = -1\n",
    "\n",
    "for i in range(len(factors_per_init)):\n",
    "\n",
    "    if diagnostics_per_init[i].regularized_loss[-1] < least_loss and diagnostics_per_init[i].n_iter < 1000 and check_degenerate(factors_per_init[i]) == False:\n",
    "\n",
    "        least_loss_run = i\n",
    "        least_loss = diagnostics_per_init[i].regularized_loss[-1]\n",
    "\n",
    "# Print feasibility gap to make sure it satisfies the requirements\n",
    "\n",
    "print(diagnostics_per_init[least_loss_run].feasibility_gaps[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Plot factors\n",
    "\n",
    "plot_results(my_generator,factor_list=[factors_per_init[least_loss_run],factors_per_init[least_loss_run-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Convergence diagnostics\n",
    "\n",
    "plot_convergence(diagnostics_per_init,factors_per_init,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
